---
layout: post
title: Elasticsearch原理
category: blog
description: Elasticsearch原理
---

## 倒排索引
通过倒排索引数据结构实现使文本可被搜索。

倒排索引被写入磁盘后是不可改变的，它永远不会修改。

## 动态更新索引

Lucene引入按段搜索的概念，每个段都是一个倒排索引。但Lucene的索引除了表示所有段的集合外，还增加了提交点的概念，提交点是一个列出所有已知段的文件，如下图：

一个Lucene索引包含一个提交点和三个段
![](/images/posts/2017-07-06-Elasticsearch原理/segment_in_Lucene.png)

一个Lucene索引在Elasticsearch称作分片。一个Elasticsearch索引是分片的集合。当 Elasticsearch在索引中搜索的时候，他发送查询到每一个属于索引的分片(Lucene索引)，然后合并每个分片的结果到一个全局的结果集。

索引的动态更新以如下流程进行工作：

1. 新文档被收集到内存索引缓存
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1102.png)
2. 不时地, 缓存被提交:
	- 一个新的段(一个追加的倒排索引)被写入磁盘。
	- 一个新的包含新段名字的提交点被写入磁盘。
	- 磁盘进行同步 — 所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件。
3. 新的段被开启，让它包含的文档可见以被搜索。
4. 内存缓存被清空，等待接收新的文档。
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1103.png)

当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。

### 删除和更新
段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del文件，文件中会列出这些被删除文档的段信息。

当一个文档被“删除”时，它实际上只是在.del文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。

文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。

## 近实时搜索
提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。但是fsync操作代价很大，如果每次索引一个文档都去执行一次的话会造成很大的性能问题。需要一个更轻量的方式来使一个文档可被搜索，这意味着fsync 要从整个过程中被移除。

在Elasticsearch和磁盘之间是文件系统缓存。在内存索引缓冲区中的文档会被写入到一个新的段中，但是这里新段会被先写入到文件系统缓存。
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1105.png)

### refresh API
在Elasticsearch中，写入和打开一个新段的轻量的过程叫做refresh。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说Elasticsearch是近实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。

并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件， 你可能想优化索引速度而不是近实时搜索，可以通过设置refresh_interval，降低每个索引的刷新频率：
	
	//每30秒刷新 my_logs 索引
	PUT /my_logs
	{
	  "settings": {
	    "refresh_interval": "30s"
	  }
	}
	
在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：

	//关闭自动刷新
	PUT /my_logs/_settings
	{ "refresh_interval": -1 } 
	//每秒自动刷新
	PUT /my_logs/_settings
	{ "refresh_interval": "1s" } 
	
## 持久化变更
通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生了变化的文档怎么办？

Elasticsearch增加了一个translog，或者叫事务日志，在每一次对Elasticsearch 进行操作时均进行了日志记录。通过translog，整个流程看起来是下面这样：

1. 一个文档被索引之后，就会被添加到内存缓冲区，并且追加到translog中
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1106.png)
2. 分片每秒被刷新（refresh）一次：
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1107.png)
	- 这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。
	- 这个段被打开，使其可被搜索。
	- 内存缓冲区被清空。
3. 更多的文档被添加到内存缓冲区和追加到事务日志
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1108.png)
4. 每隔一段时间(例如translog变得越来越大或者索引被刷新(flush))，一个新的translog被创建，并且一个全量提交被执行
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1109.png)
	- 所有在内存缓冲区的文档都被写入一个新的段。
	- 缓冲区被清空。
	- 一个提交点被写入硬盘。
	- 文件系统缓存通过fsync被刷新（flush）。
	- 老的translog被删除。

translog提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放translog中所有在最后一次提交后发生的变更操作。

translog也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。

### flush API
这个执行一个提交并且截断translog的行为在Elasticsearch被称作一次flush。 分片每30分钟被自动刷新（flush），或者在translog太大的时候也会刷新。

flush API可以被用来执行一个手工的刷新（flush）:

	POST /blogs/_flush
	
# 段合并
由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。每个段会消耗CPU的时钟周、文件句柄和内存，并且每个搜索请求都必须轮流检查每个段，所以段越多，搜索也就越慢。

Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。

段合并的时候会将那些旧的已删除文档 从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。

启动段合并不需要你做任何事。进行索引和搜索时会自动进行。

两个提交了的段和一个未提交的段正在被合并到一个更大的段：
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1110.png)
一旦合并结束，老的段被删除
![](/images/posts/2017-07-06-Elasticsearch原理/elas_1111.png)

### optimize API
optimize API可看做是强制合并API 。它会将一个分片强制合并到max_num_segments参数指定大小的段数目。这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。

通常用于老的只读的索引

	//合并索引中的每个分片为一个单独的段
	POST /logstash-2014-10/_optimize?max_num_segments=1